{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdO_RxQZLahB"
   },
   "source": [
    "# Demo for paper \"First Order Motion Model for Image Animation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCDNKsEGLtR6"
   },
   "source": [
    "**Clone repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "UCMFMJV7K-ag",
    "outputId": "d4187a1d-60b7-46d5-cf05-b5b555d11138"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/AliaksandrSiarohin/first-order-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsgVK1EURXkd"
   },
   "source": [
    "**sample data: https://drive.google.com/drive/folders/1kZ1gCnpfU0BnpdU47pLM_TQ6RypDDqgw?usp=sharing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rW-ipQXPOWUo"
   },
   "source": [
    "**Load driving video and source image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "Oxi6-riLOgnm",
    "outputId": "df5ef72c-6133-4607-8684-045613fd81f2"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "source_image = imageio.imread('./data/02.png')\n",
    "driving_video = imageio.mimread('./data/04.mp4')\n",
    "\n",
    "\n",
    "#Resize image and video to 256x256\n",
    "\n",
    "source_image = resize(source_image, (256, 256))[..., :3]\n",
    "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
    "\n",
    "def display(source, driving, generated=None):\n",
    "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
    "\n",
    "    ims = []\n",
    "    for i in range(len(driving)):\n",
    "        cols = [source]\n",
    "        cols.append(driving[i])\n",
    "        if generated is not None:\n",
    "            cols.append(generated[i])\n",
    "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
    "        plt.axis('off')\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
    "    plt.close()\n",
    "    return ani\n",
    "    \n",
    "\n",
    "# HTML(display(source_image, driving_video).to_html5_video())\n",
    "\n",
    "# pip install imageio-ffmpeg\n",
    "# pip install scikit-imag\n",
    "# conda install -c conda-forge ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjM7ubVfWrwT"
   },
   "source": [
    "**Create a model and load checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FQiXqQPWt5B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\datta\\OneDrive - HKUST Connect\\GIFShop Wizard\\rebased github repo\\vision\\first_order_motion\\model\\demo.py:28: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "from model.demo import load_checkpoints\n",
    "generator, kp_detector = load_checkpoints(config_path='./model/config/vox-256.yaml', \n",
    "                            checkpoint_path='vox-cpk.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdFdasHEj3t7"
   },
   "source": [
    "**Perform image animation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "SB12II11kF4c",
    "outputId": "c7f18b37-0d41-4761-e354-5b0c36cae30d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 211/211 [00:11<00:00, 17.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from model.demo import make_animation\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n",
    "\n",
    "#save resulting video\n",
    "imageio.mimsave('./output/generated_RelativeKeypointDisplacement.mp4', [img_as_ubyte(frame) for frame in predictions])\n",
    "#video can be downloaded from /content folder\n",
    "\n",
    "# HTML(display(source_image, driving_video, predictions).to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tJN01xQCpqH"
   },
   "source": [
    "**In the cell above we use relative keypoint displacement to animate the objects. We can use absolute coordinates instead,  but in this way all the object proporions will be inherited from the driving video. For example Putin haircut will be extended to match Trump haircut.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "aOE_W_kfC9aX",
    "outputId": "de247531-c930-45a0-df41-e19a9373df2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 211/211 [00:10<00:00, 19.44it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=False, adapt_movement_scale=True)\n",
    "imageio.mimsave('./output/generated_AbsoluteKeypointDisplacement.mp4', [img_as_ubyte(frame) for frame in predictions])\n",
    "# HTML(display(source_image, driving_video, predictions).to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnXrecuX6_Kw"
   },
   "source": [
    "## Running on your data\n",
    "\n",
    "**First we need to crop a face from both source image and video, while simple graphic editor like paint can be used for cropping from image. Cropping from video is more complicated. You can use ffpmeg for this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "brJlA_5o72Xc",
    "outputId": "75c10f77-409d-4793-b0cc-263bb20e6f76"
   },
   "outputs": [],
   "source": [
    "# !ffmpeg -i /content/gdrive/My\\ Drive/first-order-motion-model/07.mkv -ss 00:08:57.50 -t 00:00:08 -filter:v \"crop=600:600:760:50\" -async 1 hinton.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSHSxV8iGybI"
   },
   "source": [
    "**Another posibility is to use some screen recording tool, or if you need to crop many images at ones use face detector(https://github.com/1adrianb/face-alignment) , see https://github.com/AliaksandrSiarohin/video-preprocessing for preprcessing of VoxCeleb.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "d8kQ3U7MHqh-",
    "outputId": "e1369c7c-8b23-4f9a-b6bc-9edd73c1f174"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:02<00:00, 18.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# source_image = imageio.imread('./data/02.png')\n",
    "# driving_video = imageio.mimread('04.mp4', memtest=False)\n",
    "source_image = imageio.imread('./data/02.png')\n",
    "driving_video = imageio.mimread('./data/DZ1BJU.gif')\n",
    "# Driving video can accept both .gif and .mp4 input\n",
    "\n",
    "\n",
    "#Resize image and video to 256x256\n",
    "\n",
    "source_image = resize(source_image, (256, 256))[..., :3]\n",
    "driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
    "\n",
    "predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True,\n",
    "                             adapt_movement_scale=True)\n",
    "\n",
    "# HTML(display(source_image, driving_video, predictions).to_html5_video())\n",
    "\n",
    "#save resulting video\n",
    "imageio.mimsave('./output/generated_RelativeKeypointDisplacement.mp4', [img_as_ubyte(frame) for frame in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faces\n",
    "# source_image = imageio.imread('./data/02.png')\n",
    "# driving_video = imageio.mimread('./data/04.mp4')\n",
    "\n",
    "# supposedly any image/video pairs should work as long as user cropped them already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python firstordermotion.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "first-order-model-demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
